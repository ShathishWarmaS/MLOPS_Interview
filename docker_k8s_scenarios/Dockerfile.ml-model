# Multi-stage Dockerfile for ML Model Serving
# Scenario: Optimize Docker image size and build time

# Build stage
FROM python:3.9-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Production stage
FROM python:3.9-slim

# Create non-root user
RUN useradd --create-home --shell /bin/bash mluser

WORKDIR /app

# Copy dependencies from builder stage
COPY --from=builder /root/.local /home/mluser/.local

# Copy application code
COPY --chown=mluser:mluser . .

# Set environment variables
ENV PATH=/home/mluser/.local/bin:$PATH
ENV PYTHONPATH=/app
ENV MODEL_PATH=/app/models/model.pkl
ENV PORT=8000

# Switch to non-root user
USER mluser

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:${PORT}/health || exit 1

# Expose port
EXPOSE ${PORT}

# Run application
CMD ["python", "serve.py"]

# INTERVIEW QUESTIONS:
# 1. Why use multi-stage builds?
# 2. How would you optimize this further?
# 3. What security considerations are implemented?
# 4. How would you handle secrets in this container?