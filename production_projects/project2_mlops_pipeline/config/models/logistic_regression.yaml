# Logistic Regression Model Configuration

model:
  name: logistic_regression
  type: LogisticRegression
  framework: sklearn
  version: "1.0"
  
# Hyperparameters
hyperparameters:
  # Regularization
  penalty: l2
  C: 1.0
  l1_ratio: null  # Only for elasticnet penalty
  
  # Solver configuration
  solver: lbfgs
  max_iter: 1000
  tol: 1e-4
  
  # Other parameters
  fit_intercept: true
  intercept_scaling: 1.0
  class_weight: "balanced"
  random_state: 42
  
  # Multi-class strategy
  multi_class: auto
  dual: false
  
  # Convergence
  warm_start: false
  n_jobs: -1

# Hyperparameter Search Space
hyperparameter_search:
  method: grid_search  # grid_search, random_search, bayesian
  n_trials: 50
  
  search_space:
    C:
      type: log_uniform
      low: 0.001
      high: 100
    
    penalty:
      type: choice
      values: ["l1", "l2", "elasticnet"]
    
    solver:
      type: choice
      values: ["liblinear", "lbfgs", "newton-cg", "sag", "saga"]
    
    l1_ratio:
      type: uniform
      low: 0.1
      high: 0.9
      condition: "penalty == 'elasticnet'"
    
    max_iter:
      type: choice
      values: [500, 1000, 2000, 5000]
    
    class_weight:
      type: choice
      values: [null, "balanced"]

# Training Configuration
training:
  validation_strategy: stratified_kfold
  cv_folds: 5
  scoring_metric: roc_auc
  
  early_stopping:
    enabled: false  # Not supported by sklearn LogisticRegression
  
  regularization:
    l1_alpha: 0.01
    l2_alpha: 0.01
    elastic_net_ratio: 0.5

# Feature Configuration
features:
  selection:
    enabled: true
    method: l1_regularization
    threshold: 0.001
    
  importance:
    method: coefficients
    abs_values: true
    
  preprocessing:
    scaling: standard  # Required for logistic regression
    encoding:
      categorical: onehot
      missing_values: mean
    
    feature_engineering:
      polynomial_features: false
      interaction_features: false
      polynomial_degree: 2

# Model Validation
validation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    - log_loss
    - confusion_matrix
    - classification_report
  
  thresholds:
    min_accuracy: 0.70
    min_precision: 0.65
    min_recall: 0.65
    min_f1_score: 0.65
    min_roc_auc: 0.75
    max_log_loss: 0.7
  
  cross_validation:
    enabled: true
    folds: 5
    stratified: true
    shuffle: true
  
  calibration:
    enabled: true
    method: isotonic  # isotonic, sigmoid
    cv_folds: 3

# Interpretability
interpretability:
  coefficient_analysis:
    enabled: true
    plot: true
    top_features: 20
    confidence_intervals: true
  
  odds_ratios:
    enabled: true
    confidence_level: 0.95
  
  shap_analysis:
    enabled: true
    sample_size: 1000
    plots: ["summary", "waterfall", "force"]
  
  lime_analysis:
    enabled: true
    n_samples: 5000
    n_features: 10

# Model Monitoring
monitoring:
  drift_detection:
    feature_drift: true
    prediction_drift: true
    coefficient_drift: true
    
  performance_monitoring:
    enabled: true
    metrics: ["accuracy", "roc_auc", "log_loss"]
    threshold_degradation: 0.05
  
  data_quality:
    missing_values_threshold: 0.1
    outlier_detection: true
    feature_correlation_monitoring: true

# Deployment Configuration
deployment:
  model_format: pickle
  compression: true
  
  inference:
    batch_size: 5000
    parallel_predictions: false  # Usually fast enough
    probability_output: true
    threshold_optimization: true
  
  scaling:
    auto_scaling: true
    min_instances: 1
    max_instances: 5
    target_latency_ms: 10

# Resource Requirements
resources:
  training:
    cpu_cores: 2
    memory_gb: 4
    gpu_required: false
    estimated_time_minutes: 5
  
  inference:
    cpu_cores: 1
    memory_gb: 1
    gpu_required: false
    latency_target_ms: 10

# Model Metadata
metadata:
  description: "Logistic regression classifier for binary and multiclass classification"
  author: "MLOps Team"
  tags: ["classification", "linear", "interpretable", "fast"]
  
  strengths:
    - "Fast training and inference"
    - "Highly interpretable coefficients"
    - "Good baseline for linear relationships"
    - "Probability estimates well-calibrated"
    - "Memory efficient"
    - "No hyperparameter tuning required for basic use"
  
  limitations:
    - "Assumes linear relationship"
    - "Sensitive to outliers"
    - "Requires feature scaling"
    - "May underfit complex patterns"
    - "Sensitive to correlated features"
  
  use_cases:
    - "Linear classification problems"
    - "When interpretability is crucial"
    - "Baseline model"
    - "Real-time inference requirements"
    - "When training data is limited"
    - "Probability calibration needed"

# Advanced Configuration
advanced:
  solver_specific:
    liblinear:
      dual: false
      penalty: ["l1", "l2"]
      suitable_for: "small datasets"
    
    lbfgs:
      penalty: ["l2"]
      memory_efficient: true
      suitable_for: "small to medium datasets"
    
    newton_cg:
      penalty: ["l2"]
      suitable_for: "large datasets"
    
    sag:
      penalty: ["l2"]
      fast_convergence: true
      suitable_for: "large datasets"
    
    saga:
      penalty: ["l1", "l2", "elasticnet"]
      suitable_for: "large datasets with sparse features"
  
  regularization_guide:
    l1:
      effect: "feature selection"
      sparsity: "high"
      use_case: "feature selection needed"
    
    l2:
      effect: "coefficient shrinkage"
      sparsity: "low"
      use_case: "standard regularization"
    
    elasticnet:
      effect: "combination of L1 and L2"
      sparsity: "medium"
      use_case: "correlated features"

# Troubleshooting
troubleshooting:
  convergence_issues:
    increase_max_iter: true
    scale_features: true
    adjust_tolerance: true
    change_solver: true
  
  poor_performance:
    feature_engineering: true
    regularization_tuning: true
    class_balancing: true
    threshold_tuning: true